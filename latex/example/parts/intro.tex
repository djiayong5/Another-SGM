\startprefacepage

Существуют различные способы повышения эффективности скалярной оптимизации. Некоторые из них основаны на использовании вспомогательных критериев. Например, задача скалярной оптимизации может быть преобразована в задачу многокритериальной оптимизации путем разработки дополнительных критериев, обладающих определенными заранее заданными свойствами, что позволяет избежать остановки поиска решения в локальном оптимуме~\cite{mh-iff}. Также в качестве источника вспомогательных критериев может выступать предметная область~\cite{master}. В этом случае свойства критериев чаще всего заранее не известны, причем они могут меняться в зависимости от того, на каком этапе находится процесс оптимизации. 

В данной работе предлагается метод повышения эффективности скалярной оптимизации с использованием вспомогательных критериев. Предполагается, что набор критериев задан заранее и об их свойствах ничего не известно. Таким образом, возникает задача скалярной оптимизации со вспомогательными критериями. Важно отметить, что задача оптимизации самих вспомогательных критериев не ставится. В то же время, в традиционной теории многокритериальной оптимизации одинаково важны все критерии~\cite{criteries, multicriteria, multievol}. Существуют также задачи, в которых некоторые критерии представляют меньший интерес, чем остальные, хотя такие критерии по-прежнему оптимизируются~\cite{ref-point}. В поставленной задаче должен быть оптимизирован только один \emph{целевой} критерий.

Описанная задача решается с применением эволюционного алгоритма (Evolutionary Algorithm, EA)~\cite{nature-inspired, essentials, mitchell-ga, skobtsov}, настраиваемого во время выполнения с помощью обучения с подкреплением (Reinforcement Learning, RL)~\cite{alpaydin, gosavi, sutton, survey}. В дальнейшем предлагаемый метод будет называться EA~+~RL. Таким образом, метод решения описанной задачи основан на настройке эволюционного алгоритма во время выполнения. Вспомогательные критерии, так же как и целевой критерий, задаются с помощью функций приспособленности. Метод EA~+~RL позволяет выбирать из заранее подготовленного набора наиболее эффективную ФП для генерации каждого последующего поколения эволюционного алгоритма. В других существующих методах настройки эволюционных алгоритмов обычно настраиваются вещественные параметры фиксированной ФП, причем настройка ФП освещена в литературе в меньшей степени, чем настройка иных параметров ЭА~\cite{adjusting, fuzzy, filtered-ff, es-rl}. 

Новизна предлагаемого подхода заключается в использовании обучения с подкреплением для выбора ФП эволюционного алгоритма. Обучение с подкреплением является современной развивающейся технологией, применимость которой в различных областях человеческой деятельности находится в процессе исследования~\cite{gosavi, survey}. Насколько известно автору, существует лишь две работы, в которых исследуется возможность использования обучения с подкреплением для настройки эволюционного алгоритма~\cite{ea-rl, es-rl}. В обеих работах рассматривается настройка вещественных параметров, таких как, например, вероятность мутации или размер поколения. Данная работа вносит вклад в исследование применимости обучения с подкреплением к настройке ФП. 

Предлагаемый метод применен к решению различных модельных задач. В частности, решалась задача оптимизации функции H-IFF~\cite{h-iff}, применяемая для тестирования генетических алгоритмов, а также разработки методов предотвращения остановки процесса оптимизации в локальном оптимуме, основанных на сведении однокритериальной оптимизации к многокритериальной. При решении этой задачи применение разработанного метода к настройке 1~+~1 эволюционной стратегии \cite{nature-inspired, essentials, skobtsov} позволило стабильно выращивать лучшие возможные особи за фиксированное число поколений, в то время как стратегия без настройки не справилась с этой задачей.
Также в работе представлены результаты решения модельных задач, иллюстрирующие такие особенности метода, как динамическое переключение ФП, выгодных на различных этапах оптимизации, и устойчивость метода в случае наличия в наборе вспомогательной ФП, использование которой ведет к быстрому ухудшению целевой ФП.

Предлагаемый метод не уступает алгоритму многокритериальной оптимизации PESA~\cite{pesa}, показывающему лучшие результаты решения многокритериального варианта задачи H-IFF~\cite{mh-iff}. Более того, при решении  модификации этой задачи, в которой присутствует не коррелирующий с целевой ФП критерий, разработанный метод EA~+~RL позволяет выращивать лучшие возможные особи в отличие от алгоритма многокритериальной оптимизации PESA-II, входящего в число самых эффективных методов многокритериальной оптимизации, известных на данный момент~\cite{pesa-ii, coello}. Это может быть объяснено тем, что обучение позволяет не учитывать неэффективные критерии, в то время как алгоритмы многокритериальной оптимизации стремятся оптимизировать все критерии. Таким образом, метод EA~+~RL применим для более широкого множества вспомогательных критериев, чем методы многокритериальной оптимизации, используемые для повышения эффективности скалярной оптимизации.
