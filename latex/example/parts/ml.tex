\section{Машинное обучение}
\label{ml}	
	Методы машинного обучения \cite{mitchell-ml} предоставляют обобщенные подходы к решению задач, что позволяет применять их во многих областях: от разработки оптимальных стратегий игр и управления техническими процессами до решения задач распознавания и классификации. Рассмотрим основные подходы, применяющиеся в машинном обучении, с целью анализа их применимости к выбору вспомогательных функций приспособленности генетического алгоритма.
	\subsection{Деревья принятия решений и обучение концептам}
	Деревья принятия решений используются для классификации данных. Они позволяют аппроксимировать заданную булевскую функцию. Обучение ведется на конечных наборах дискретных атрибутов, для каждого из которых задано значение аппроксимируемой функции. Также для классификации данных в схожих условиях применяется обучение концептам \cite{mitchell-ml}.
	Требование наличия готового набора тестовых примеров, их дискретный характер, а также сама цель подобных методов, заключающаяся в классификации данных, затрудняют их применение к решению поставленной задачи.
	\subsection{Нейронные сети}	
	Помимо аппроксимации булевских функций и решения задач классификации, некоторые виды нейронных сетей позволяют аппроксимировать нелинейные функции с вещественными значениями. Большинство модификаций нейронных сетей предполагает наличие заранее подготовленного обучающего набора, хотя существуют подходы, позволяющие сделать обучение нейронной сети инкрементальным \cite{incremental}.
	Была предпринята попытка аппроксимации зависимости целевой функции приспособленности от дополнительных функций с помощью многослойной нейронной сети, составленной из нелинейных перцептронов и использующей алгоритм обратного распространения ошибки \cite{alpaydin, systems}. Также применялась реализация нейронной сети из библиотеки алгоритмов машинного обучения \emph{Encog}~\cite{encog}, в которой использовался алгоритм \emph{Quickprop} \cite{quickprop}. Эти нейронные сети показывали хорошие результаты аппроксимации несложных вещественных функций, но для решения поставленной задачи их точности не хватило. Однако дальнейшее исследование возможности использования нейронных сетей, особенно их инкрементальных модификаций, для выбора функций приспособленности кажется целесообразным.
	\subsection{Байесовское обучение}
	К методом байесовского обучения относятся, например, классификатор Гиббса и наивный байесовский классификатор \cite{mitchell-ml}. Они позволяют решать задачи классификации с большим количеством параметров. Обучаются на заранее подготовленных наборах тестовых примеров. Применение подобных методов для решения поставленной задачи затруднительно, так как ее сведение к задаче классификации неочевидно.
	\subsection{Алгоритмы кластеризации}
	Задача кластеризации \cite{alpaydin} возникает в анализе данных, распознавании образов, а также в биоинформатике, например, при выделении семейств генов, отвечающих за то или иное биологическое свойство. Алгоритмы кластеризации позволяют разделить объекты одной природы на несколько групп таким образом, чтобы объекты каждой группы были близки между собой, а объекты из разных групп существенно различались. Поставленная задача не относится к задачам кластеризации.